#!/usr/bin/env python3
"""
LangGraph 101 - Production FastAPI Streaming Bridge
=================================================

Production-ready FastAPI bridge with streaming support, WebSocket integration,
and comprehensive service orchestration for Phase 4.

Features:
- Real-time streaming chat endpoints
- WebSocket support for live communication
- Advanced authentication and authorization
- Rate limiting and DDoS protection
- Comprehensive monitoring and analytics
- Service health checking and discovery
- Load balancing and failover capabilities

Author: GitHub Copilot
Date: 2024
"""

import asyncio
import json
import logging
import time
import uuid
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Set

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Depends, Request, BackgroundTasks, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field, validator
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response

# Import streaming components
from langgraph_streaming_agent_enhanced import (
    get_streaming_agent,
    get_multi_agent_orchestrator,
    StreamingAgent,
    MultiAgentOrchestrator,
    StreamingMode,
    StreamingConfig
)
from langgraph_websocket_handler import (
    get_websocket_handler,
    WebSocketHandler
)
from langgraph_workflow_manager import (
    get_workflow_manager,
    WorkflowManager
)

# Import existing components
try:
    from advanced_auth import AuthenticationManager
    from enhanced_rate_limiting import RateLimitManager
    from analytics_logger import AnalyticsLogger
    from app_health import HealthChecker
    AUTH_AVAILABLE = True
except ImportError:
    AUTH_AVAILABLE = False
    logging.warning("Advanced auth components not available")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Security
security = HTTPBearer(auto_error=False)

# Pydantic Models
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=8000, description="Chat message")
    agent_id: str = Field(default="general", description="Agent to use")
    session_id: Optional[str] = Field(None, description="Session ID")
    streaming: bool = Field(default=True, description="Enable streaming")
    persona: str = Field(default="default", description="Persona to use")
    
    @validator('message')
    def validate_message(cls, v):
        if not v.strip():
            raise ValueError('Message cannot be empty')
        return v.strip()

class ChatResponse(BaseModel):
    response: str
    session_id: str
    agent_id: str
    persona: str
    timestamp: str
    streaming: bool
    metadata: Dict[str, Any] = {}

class AgentConfigModel(BaseModel):
    agent_id: str = Field(..., min_length=1, max_length=50)
    enable_thinking: bool = True
    chunk_size: int = Field(default=50, ge=10, le=500)
    delay_ms: int = Field(default=10, ge=0, le=1000)
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: int = Field(default=2000, ge=100, le=8000)

class WorkflowRequest(BaseModel):
    workflow_id: str
    initial_message: str
    agent_sequence: List[str]
    config: Dict[str, Any] = {}

class SystemStatus(BaseModel):
    status: str
    uptime: str
    active_connections: int
    active_sessions: int
    available_agents: List[str]
    available_workflows: List[str]
    system_metrics: Dict[str, Any]
    timestamp: str

# Global state management
class AppState:
    def __init__(self):
        self.start_time = datetime.now()
        self.streaming_agent: Optional[StreamingAgent] = None
        self.orchestrator: Optional[MultiAgentOrchestrator] = None
        self.websocket_handler: Optional[WebSocketHandler] = None
        self.workflow_manager: Optional[WorkflowManager] = None
        self.auth_manager: Optional[Any] = None
        self.rate_limiter: Optional[Any] = None
        self.analytics: Optional[Any] = None
        self.health_checker: Optional[Any] = None
        self.active_connections: Set[str] = set()

app_state = AppState()

# Middleware
class SecurityMiddleware(BaseHTTPMiddleware):
    """Security middleware for request validation"""
    
    async def dispatch(self, request: Request, call_next):
        # Add security headers
        response = await call_next(request)
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        return response

class PerformanceMiddleware(BaseHTTPMiddleware):
    """Performance monitoring middleware"""
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        response = await call_next(request)
        process_time = time.time() - start_time
        response.headers["X-Process-Time"] = str(process_time)
        
        # Log performance metrics
        if app_state.analytics:
            app_state.analytics.log_request_performance(
                endpoint=str(request.url.path),
                method=request.method,
                duration=process_time,
                status_code=response.status_code
            )
        
        return response

# App lifecycle management
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management"""
    # Startup
    logger.info("üöÄ Starting LangGraph Production FastAPI Bridge...")
    
    try:
        # Initialize core components
        app_state.streaming_agent = get_streaming_agent()
        app_state.orchestrator = get_multi_agent_orchestrator()
        app_state.websocket_handler = get_websocket_handler()
        app_state.workflow_manager = get_workflow_manager()
        
        # Initialize optional components
        if AUTH_AVAILABLE:
            try:
                app_state.auth_manager = AuthenticationManager()
                app_state.rate_limiter = RateLimitManager()
                app_state.analytics = AnalyticsLogger()
                app_state.health_checker = HealthChecker()
                logger.info("‚úÖ Advanced components initialized")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Advanced components failed: {e}")
        
        # Initialize default agents
        default_agents = {
            "general": StreamingConfig(enable_thinking=True, delay_ms=15),
            "fast": StreamingConfig(enable_thinking=False, delay_ms=5, chunk_size=100),
            "creative": StreamingConfig(enable_thinking=True, delay_ms=25, chunk_size=30, temperature=0.9),
            "analytical": StreamingConfig(enable_thinking=True, delay_ms=20, chunk_size=40, temperature=0.3),
            "coding": StreamingConfig(enable_thinking=True, delay_ms=10, chunk_size=60, temperature=0.2)
        }
        
        for agent_id, config in default_agents.items():
            app_state.orchestrator.add_agent(agent_id, config)
        
        # Initialize agent in the orchestrator as well
        await app_state.streaming_agent.initialize()
        
        logger.info(f"‚úÖ Initialized {len(default_agents)} streaming agents")
        logger.info("üöÄ FastAPI Bridge startup complete")
        
    except Exception as e:
        logger.error(f"‚ùå Startup failed: {e}")
        raise
    
    yield
    
    # Shutdown
    logger.info("üõë Shutting down FastAPI Bridge...")
    
    try:
        if app_state.streaming_agent:
            await app_state.streaming_agent.shutdown()
        
        if app_state.websocket_handler:
            await app_state.websocket_handler.stop_cleanup_task()
        
        logger.info("‚úÖ Shutdown complete")
        
    except Exception as e:
        logger.error(f"‚ùå Shutdown error: {e}")

# Create FastAPI app
app = FastAPI(
    title="LangGraph Production Streaming API",
    description="Production-ready FastAPI bridge for real-time LangGraph interactions with advanced features",
    version="4.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(SecurityMiddleware)
app.add_middleware(PerformanceMiddleware)

# Dependency functions
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Get current authenticated user"""
    if not credentials and app_state.auth_manager:
        return {"user_id": "anonymous", "roles": ["user"]}
    
    if app_state.auth_manager and credentials:
        try:
            user = await app_state.auth_manager.validate_token(credentials.credentials)
            return user
        except Exception as e:
            logger.warning(f"Auth validation failed: {e}")
            raise HTTPException(status_code=401, detail="Invalid authentication")
    
    return {"user_id": "anonymous", "roles": ["user"]}

async def rate_limit_check(request: Request, user: dict = Depends(get_current_user)):
    """Check rate limiting"""
    if app_state.rate_limiter:
        try:
            await app_state.rate_limiter.check_rate_limit(
                user_id=user["user_id"],
                endpoint=str(request.url.path),
                request_type="api"
            )
        except Exception as e:
            logger.warning(f"Rate limit exceeded: {e}")
            raise HTTPException(status_code=429, detail="Rate limit exceeded")

# API Routes

@app.get("/", response_model=Dict[str, Any])
async def root():
    """API root endpoint"""
    return {
        "service": "LangGraph Production Streaming API",
        "version": "4.0.0",
        "status": "active",
        "features": [
            "real-time-streaming",
            "websocket-support", 
            "multi-agent-orchestration",
            "workflow-management",
            "advanced-analytics"
        ],
        "timestamp": datetime.now().isoformat(),
        "docs": "/docs",
        "websocket": "/ws/{user_id}",
        "health": "/health"
    }

@app.get("/health", response_model=Dict[str, Any])
async def health_check():
    """Comprehensive health check"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime": str(datetime.now() - app_state.start_time),
        "components": {
            "streaming_agent": bool(app_state.streaming_agent),
            "orchestrator": bool(app_state.orchestrator),
            "websocket_handler": bool(app_state.websocket_handler),
            "workflow_manager": bool(app_state.workflow_manager)
        }
    }
    
    if app_state.health_checker:
        try:
            detailed_health = await app_state.health_checker.get_system_health()
            health_status.update(detailed_health)
        except Exception as e:
            health_status["health_checker_error"] = str(e)
    
    return health_status

@app.get("/status", response_model=SystemStatus)
async def get_system_status(user: dict = Depends(get_current_user)):
    """Get comprehensive system status"""
    
    uptime = datetime.now() - app_state.start_time
    
    # Get active sessions
    active_sessions = 0
    if app_state.streaming_agent:
        active_sessions = len(app_state.streaming_agent.get_active_sessions())
    
    # Get available agents
    available_agents = []
    if app_state.orchestrator:
        available_agents = list(app_state.orchestrator.agents.keys())
    
    # Get available workflows
    available_workflows = []
    if app_state.workflow_manager:
        available_workflows = list(app_state.workflow_manager.workflows.keys())
    
    # Get system metrics
    system_metrics = {}
    if app_state.streaming_agent:
        system_metrics = app_state.streaming_agent.get_performance_metrics()
    
    return SystemStatus(
        status="operational",
        uptime=str(uptime),
        active_connections=len(app_state.active_connections),
        active_sessions=active_sessions,
        available_agents=available_agents,
        available_workflows=available_workflows,
        system_metrics=system_metrics,
        timestamp=datetime.now().isoformat()
    )

@app.get("/agents", response_model=Dict[str, Any])
async def get_agents(user: dict = Depends(get_current_user)):
    """Get available agents and configurations"""
    
    if not app_state.orchestrator:
        raise HTTPException(status_code=503, detail="Orchestrator not available")
    
    agents_info = {}
    for agent_id, agent in app_state.orchestrator.agents.items():
        agents_info[agent_id] = {
            "id": agent_id,
            "config": {
                "thinking_enabled": agent.config.enable_thinking,
                "chunk_size": agent.config.chunk_size,
                "delay_ms": agent.config.delay_ms,
                "temperature": agent.config.temperature,
                "max_tokens": agent.config.max_tokens
            },
            "status": "active"
        }
    
    return {
        "agents": agents_info,
        "total_count": len(agents_info),
        "timestamp": datetime.now().isoformat()
    }

@app.post("/agents", response_model=Dict[str, str])
async def create_agent(
    config: AgentConfigModel,
    user: dict = Depends(get_current_user),
    _: None = Depends(rate_limit_check)
):
    """Create a new agent with custom configuration"""
    
    if not app_state.orchestrator:
        raise HTTPException(status_code=503, detail="Orchestrator not available")
    
    # Check if agent already exists
    if config.agent_id in app_state.orchestrator.agents:
        raise HTTPException(status_code=409, detail=f"Agent {config.agent_id} already exists")
    
    # Create streaming config
    streaming_config = StreamingConfig(
        enable_thinking=config.enable_thinking,
        chunk_size=config.chunk_size,
        delay_ms=config.delay_ms,
        temperature=config.temperature,
        max_tokens=config.max_tokens
    )
    
    # Add agent to orchestrator
    app_state.orchestrator.add_agent(config.agent_id, streaming_config)
    
    # Log creation
    if app_state.analytics:
        app_state.analytics.log_agent_creation(config.agent_id, user["user_id"])
    
    return {
        "message": f"Agent {config.agent_id} created successfully",
        "agent_id": config.agent_id,
        "created_by": user["user_id"],
        "timestamp": datetime.now().isoformat()
    }

@app.post("/chat", response_model=ChatResponse)
async def chat_sync(
    request: ChatRequest,
    user: dict = Depends(get_current_user),
    _: None = Depends(rate_limit_check)
):
    """Synchronous chat endpoint"""
    
    if not app_state.streaming_agent:
        raise HTTPException(status_code=503, detail="Streaming agent not available")
    
    try:
        # Create session if needed
        session_id = request.session_id
        if not session_id:
            session_id = await app_state.streaming_agent.create_streaming_session(
                user_id=user["user_id"],
                persona_name=request.persona,
                streaming_mode=StreamingMode.TEXT
            )
        
        # Collect full response
        full_response = ""
        async for chunk in app_state.streaming_agent.stream_response(session_id, request.message, stream_chunks=False):
            if chunk.is_final:
                full_response = chunk.content
                break
        
        # Log interaction
        if app_state.analytics:
            app_state.analytics.log_chat_interaction(
                user_id=user["user_id"],
                session_id=session_id,
                agent_id=request.agent_id,
                message=request.message,
                response=full_response
            )
        
        return ChatResponse(
            response=full_response,
            session_id=session_id,
            agent_id=request.agent_id,
            persona=request.persona,
            timestamp=datetime.now().isoformat(),
            streaming=False,
            metadata={
                "user_id": user["user_id"],
                "sync": True
            }
        )
        
    except Exception as e:
        logger.error(f"‚ùå Chat error: {e}")
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@app.post("/chat/stream")
async def chat_stream(
    request: ChatRequest,
    user: dict = Depends(get_current_user),
    _: None = Depends(rate_limit_check)
):
    """Streaming chat endpoint with Server-Sent Events"""
    
    if not app_state.streaming_agent:
        raise HTTPException(status_code=503, detail="Streaming agent not available")
    
    async def generate_stream():
        try:
            # Create session if needed
            session_id = request.session_id
            if not session_id:
                session_id = await app_state.streaming_agent.create_streaming_session(
                    user_id=user["user_id"],
                    persona_name=request.persona,
                    streaming_mode=StreamingMode.EVENT_STREAM
                )
            
            # Send session info
            yield f"data: {json.dumps({'type': 'session_start', 'session_id': session_id, 'agent_id': request.agent_id})}\n\n"
            
            # Stream response
            async for chunk in app_state.streaming_agent.stream_response(session_id, request.message):
                chunk_data = {
                    "type": "chunk",
                    "chunk_id": chunk.chunk_id,
                    "content": chunk.content,
                    "chunk_type": chunk.chunk_type,
                    "is_final": chunk.is_final,
                    "timestamp": chunk.timestamp.isoformat()
                }
                yield f"data: {json.dumps(chunk_data)}\n\n"
                
                if chunk.is_final:
                    break
            
            # Send completion
            yield f"data: {json.dumps({'type': 'complete', 'timestamp': datetime.now().isoformat()})}\n\n"
            
        except Exception as e:
            logger.error(f"‚ùå Streaming error: {e}")
            error_data = {
                "type": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            yield f"data: {json.dumps(error_data)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        }
    )

@app.post("/workflows/execute")
async def execute_workflow(
    request: WorkflowRequest,
    user: dict = Depends(get_current_user),
    _: None = Depends(rate_limit_check)
):
    """Execute a multi-agent workflow"""
    
    if not app_state.workflow_manager:
        raise HTTPException(status_code=503, detail="Workflow manager not available")
    
    try:
        # Execute workflow
        results = []
        async for result in app_state.workflow_manager.execute_workflow(
            request.workflow_id,
            request.initial_message,
            user["user_id"]
        ):
            results.append(result)
        
        return {
            "workflow_id": request.workflow_id,
            "results": results,
            "executed_by": user["user_id"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Workflow execution error: {e}")
        raise HTTPException(status_code=500, detail=f"Workflow execution failed: {str(e)}")

# WebSocket endpoint
@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    """WebSocket endpoint for real-time communication"""
    
    if not app_state.websocket_handler:
        await websocket.close(code=1013)  # Service unavailable
        return
    
    # Add to active connections
    connection_id = str(uuid.uuid4())
    app_state.active_connections.add(connection_id)
    
    try:
        await app_state.websocket_handler.handle_websocket(
            websocket,
            user_id,
            metadata={"connection_id": connection_id}
        )
    finally:
        # Remove from active connections
        app_state.active_connections.discard(connection_id)

@app.get("/metrics")
async def get_metrics(user: dict = Depends(get_current_user)):
    """Get system metrics"""
    
    metrics = {
        "active_connections": len(app_state.active_connections),
        "uptime_seconds": (datetime.now() - app_state.start_time).total_seconds(),
        "timestamp": datetime.now().isoformat()
    }
    
    if app_state.streaming_agent:
        agent_metrics = app_state.streaming_agent.get_performance_metrics()
        metrics.update(agent_metrics)
    
    if app_state.analytics:
        try:
            analytics_metrics = await app_state.analytics.get_system_metrics()
            metrics["analytics"] = analytics_metrics
        except Exception as e:
            metrics["analytics_error"] = str(e)
    
    return metrics

# Background task endpoints
@app.post("/admin/cleanup")
async def admin_cleanup(
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user)
):
    """Admin endpoint for system cleanup"""
    
    # Check admin permissions
    if "admin" not in user.get("roles", []):
        raise HTTPException(status_code=403, detail="Admin access required")
    
    async def cleanup_task():
        if app_state.streaming_agent:
            await app_state.streaming_agent.cleanup_expired_sessions()
        
        if app_state.workflow_manager:
            await app_state.workflow_manager.cleanup_completed_workflows()
        
        logger.info("üßπ System cleanup completed")
    
    background_tasks.add_task(cleanup_task)
    
    return {
        "message": "Cleanup task started",
        "initiated_by": user["user_id"],
        "timestamp": datetime.now().isoformat()
    }

# Error handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url.path)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "status_code": 500,
            "timestamp": datetime.now().isoformat(),
            "path": str(request.url.path)
        }
    )

def start_production_server(
    host: str = "0.0.0.0",
    port: int = 8002,
    workers: int = 1,
    reload: bool = False
):
    """Start the production FastAPI server"""
    
    logger.info(f"üöÄ Starting LangGraph Production FastAPI server")
    logger.info(f"üì° Server: {host}:{port}")
    logger.info(f"üë• Workers: {workers}")
    logger.info(f"üîÑ Reload: {reload}")
    
    uvicorn.run(
        "fastapi_streaming_bridge:app",
        host=host,
        port=port,
        workers=workers,
        reload=reload,
        log_level="info",
        access_log=True
    )

if __name__ == "__main__":
    start_production_server(host="127.0.0.1", reload=True)
