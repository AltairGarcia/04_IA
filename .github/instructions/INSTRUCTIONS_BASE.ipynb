{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9dcf9e",
   "metadata": {},
   "source": [
    "# Mastering Python Unit Testing: Best Practices and Examples\n",
    "\n",
    "This notebook provides a comprehensive guide to Python unit testing best practices. We'll explore how to write effective, maintainable test suites that help catch bugs early and enable confident refactoring. Whether you're new to testing or looking to improve your existing test suite, this guide will provide practical advice and examples to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747fec5",
   "metadata": {},
   "source": [
    "## Why Care About Unit Testing Best Practices?\n",
    "\n",
    "Without proper practices, tests can become a source of frustration and inefficiency. Common issues include:\n",
    "\n",
    "- **Inefficient Testing**: Slow or complex tests that delay development cycles\n",
    "- **Lack of Clarity**: Badly written tests with unclear intentions\n",
    "- **Fragile Tests**: Tests that break easily with minor code changes\n",
    "- **Test Redundancy**: Duplicated logic leading to bloated test suites\n",
    "- **Non-Deterministic Tests**: Flaky tests that produce inconsistent results\n",
    "- **Inadequate Coverage**: Missing key scenarios, especially edge cases\n",
    "\n",
    "In this notebook, we'll address these challenges with guidelines and examples to write tests that are fast, simple, readable, deterministic, and well-integrated into your development process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb48e71",
   "metadata": {},
   "source": [
    "## Popular Python Testing Frameworks\n",
    "\n",
    "Python offers several testing frameworks. We'll focus primarily on pytest in our examples, but the principles apply across frameworks:\n",
    "\n",
    "- **pytest**: Modern, powerful, and easy to use (our primary focus)\n",
    "- **unittest**: Standard library module based on JUnit\n",
    "- **nose2**: Extended unittest framework\n",
    "- **doctest**: Test interactive examples in docstrings\n",
    "\n",
    "Let's install pytest for our examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66efb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pytest\n",
    "!pip install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8976cb4",
   "metadata": {},
   "source": [
    "## Best Practice 1: Keep Tests Atomic and Independent\n",
    "\n",
    "Each test should test a single unit of code in isolation and should not depend on other tests. This ensures tests are repeatable and failures can be easily traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23db8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to test\n",
    "def sum_list(numbers):\n",
    "    \"\"\"Calculate the sum of a list of numbers.\"\"\"\n",
    "    return sum(numbers)\n",
    "\n",
    "# Good: Atomic and independent tests\n",
    "def test_sum_list_empty():\n",
    "    \"\"\"Test sum_list with empty list.\"\"\"\n",
    "    assert sum_list([]) == 0\n",
    "    \n",
    "def test_sum_list_single_item():\n",
    "    \"\"\"Test sum_list with a single item.\"\"\"\n",
    "    assert sum_list([5]) == 5\n",
    "    \n",
    "def test_sum_list_multiple_items():\n",
    "    \"\"\"Test sum_list with multiple items.\"\"\"\n",
    "    assert sum_list([1, 2, 3]) == 6\n",
    "    \n",
    "# Bad: Non-atomic test that tests multiple behaviors at once\n",
    "def test_sum_list_all_cases():\n",
    "    \"\"\"Test sum_list with various inputs.\"\"\"\n",
    "    assert sum_list([]) == 0\n",
    "    assert sum_list([5]) == 5\n",
    "    assert sum_list([1, 2, 3]) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa086c35",
   "metadata": {},
   "source": [
    "## Best Practice 2: Use Descriptive Test Names\n",
    "\n",
    "Test names should clearly describe what's being tested. Good naming makes it easier to understand the purpose of each test and simplifies debugging when tests fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e210344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function\n",
    "def is_palindrome(string):\n",
    "    \"\"\"Check if a string is a palindrome.\"\"\"\n",
    "    return string == string[::-1]\n",
    "\n",
    "# Good: Descriptive test names\n",
    "def test_is_palindrome_with_single_character():\n",
    "    assert is_palindrome(\"a\") == True\n",
    "    \n",
    "def test_is_palindrome_with_palindrome_word():\n",
    "    assert is_palindrome(\"racecar\") == True\n",
    "    \n",
    "def test_is_palindrome_with_non_palindrome_word():\n",
    "    assert is_palindrome(\"hello\") == False\n",
    "    \n",
    "def test_is_palindrome_with_empty_string():\n",
    "    assert is_palindrome(\"\") == True\n",
    "    \n",
    "# Bad: Vague test names\n",
    "def test_palindrome_1():\n",
    "    assert is_palindrome(\"a\") == True\n",
    "    \n",
    "def test_palindrome_2():\n",
    "    assert is_palindrome(\"racecar\") == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acad416",
   "metadata": {},
   "source": [
    "## Best Practice 3: Use Assertions to Validate Results\n",
    "\n",
    "Assertions validate that your code is working as expected. In pytest, the `assert` statement is the primary way to check for expected outcomes. You can add messages to make failures more informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function\n",
    "def divide(a, b):\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "# Good: Informative assertions\n",
    "def test_divide_normal_case():\n",
    "    result = divide(10, 2)\n",
    "    assert result == 5, f\"Expected 5 but got {result}\"\n",
    "    \n",
    "def test_divide_by_zero():\n",
    "    try:\n",
    "        divide(10, 0)\n",
    "        assert False, \"Expected ValueError but no exception was raised\"\n",
    "    except ValueError:\n",
    "        assert True\n",
    "        \n",
    "# Better approach for testing exceptions with pytest\n",
    "import pytest\n",
    "\n",
    "def test_divide_by_zero_with_pytest():\n",
    "    with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n",
    "        divide(10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656409ce",
   "metadata": {},
   "source": [
    "## Best Practice 4: Use Fixtures for Common Test Data\n",
    "\n",
    "Test fixtures provide a way to set up common test data that can be reused across multiple tests. This reduces duplication and makes tests more maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with pytest fixtures\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_numbers():\n",
    "    \"\"\"Fixture providing a list of sample numbers.\"\"\"\n",
    "    return [1, 2, 3, 4, 5]\n",
    "\n",
    "@pytest.fixture\n",
    "def empty_list():\n",
    "    \"\"\"Fixture providing an empty list.\"\"\"\n",
    "    return []\n",
    "\n",
    "# Tests using fixtures\n",
    "def test_sum_list_with_fixture(sample_numbers):\n",
    "    assert sum_list(sample_numbers) == 15\n",
    "    \n",
    "def test_sum_list_empty_with_fixture(empty_list):\n",
    "    assert sum_list(empty_list) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97e93a",
   "metadata": {},
   "source": [
    "## Best Practice 5: Write Docstrings for Each Test Method\n",
    "\n",
    "Docstrings explain the purpose of each test, making your test suite more understandable. They help others (and your future self) understand what the test is verifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89807f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_divide_edge_cases():\n",
    "    \"\"\"Test division function with various edge cases.\n",
    "    \n",
    "    This test verifies:\n",
    "    1. Very large numerators\n",
    "    2. Very small denominators\n",
    "    3. Negative number division\n",
    "    \"\"\"\n",
    "    assert divide(1000000, 2) == 500000\n",
    "    assert divide(10, 0.1) == 100\n",
    "    assert divide(-10, 5) == -2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f33fe85",
   "metadata": {},
   "source": [
    "## Best Practice 6: Don't Repeat Yourself (DRY)\n",
    "\n",
    "Avoid code duplication in tests. Use helper functions, fixtures, and parameterization to eliminate repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parameterized tests\n",
    "import pytest\n",
    "\n",
    "# Function to test\n",
    "def is_even(number):\n",
    "    \"\"\"Check if a number is even.\"\"\"\n",
    "    return number % 2 == 0\n",
    "\n",
    "# Bad: Repetitive tests\n",
    "def test_is_even_2():\n",
    "    assert is_even(2) == True\n",
    "    \n",
    "def test_is_even_4():\n",
    "    assert is_even(4) == True\n",
    "    \n",
    "def test_is_odd_3():\n",
    "    assert is_even(3) == False\n",
    "    \n",
    "def test_is_odd_5():\n",
    "    assert is_even(5) == False\n",
    "    \n",
    "# Good: Parameterized tests\n",
    "@pytest.mark.parametrize(\"number, expected\", [\n",
    "    (2, True),\n",
    "    (4, True),\n",
    "    (3, False),\n",
    "    (5, False),\n",
    "])\n",
    "def test_is_even_parameterized(number, expected):\n",
    "    \"\"\"Test is_even function with various inputs.\"\"\"\n",
    "    assert is_even(number) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a44f8e",
   "metadata": {},
   "source": [
    "## Best Practice 7: Use setUp() and tearDown() Methods (or Fixtures)\n",
    "\n",
    "Use setUp and tearDown methods (or pytest fixtures) to handle test setup and cleanup. This ensures that each test starts with a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0202b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using unittest style\n",
    "import unittest\n",
    "\n",
    "class TestDatabase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up test fixtures before each test method.\"\"\"\n",
    "        self.db = {\n",
    "            \"users\": []\n",
    "        }\n",
    "        # Populate with test data\n",
    "        self.db[\"users\"].append({\"id\": 1, \"name\": \"Alice\"})\n",
    "        \n",
    "    def tearDown(self):\n",
    "        \"\"\"Clean up after each test method.\"\"\"\n",
    "        self.db = None\n",
    "        \n",
    "    def test_add_user(self):\n",
    "        \"\"\"Test adding a user to the database.\"\"\"\n",
    "        self.db[\"users\"].append({\"id\": 2, \"name\": \"Bob\"})\n",
    "        self.assertEqual(len(self.db[\"users\"]), 2)\n",
    "        \n",
    "    def test_user_count(self):\n",
    "        \"\"\"Test the initial user count.\"\"\"\n",
    "        self.assertEqual(len(self.db[\"users\"]), 1)\n",
    "\n",
    "# Using pytest fixtures with setup and teardown\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def database():\n",
    "    # Setup\n",
    "    db = {\"users\": []}\n",
    "    db[\"users\"].append({\"id\": 1, \"name\": \"Alice\"})\n",
    "    \n",
    "    # Provide the fixture value\n",
    "    yield db\n",
    "    \n",
    "    # Teardown\n",
    "    db = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444caea",
   "metadata": {},
   "source": [
    "## Best Practice 8: Tests Should Be Fast\n",
    "\n",
    "Slow tests discourage developers from running them frequently, which defeats their purpose. Keep your tests as fast as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a474152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad: Slow test with unnecessary operation\n",
    "import time\n",
    "\n",
    "def test_slow_operation():\n",
    "    \"\"\"Test that unnecessarily sleeps.\"\"\"\n",
    "    time.sleep(2)  # Don't do this in real tests!\n",
    "    result = 1 + 1\n",
    "    assert result == 2\n",
    "    \n",
    "# Good: Use mocks for external dependencies\n",
    "from unittest.mock import patch, MagicMock\n",
    "\n",
    "def fetch_data_from_api(url):\n",
    "    \"\"\"Function that would normally make a slow API call.\"\"\"\n",
    "    # In real code, this would make an HTTP request\n",
    "    pass\n",
    "\n",
    "def process_data(url):\n",
    "    \"\"\"Process data fetched from an API.\"\"\"\n",
    "    data = fetch_data_from_api(url)\n",
    "    # Do something with the data\n",
    "    return len(data) if data else 0\n",
    "\n",
    "# Fast test using mock\n",
    "def test_process_data():\n",
    "    \"\"\"Test process_data function with mocked API call.\"\"\"\n",
    "    with patch('__main__.fetch_data_from_api') as mock_fetch:\n",
    "        # Configure the mock to return a predefined response\n",
    "        mock_fetch.return_value = [\"item1\", \"item2\", \"item3\"]\n",
    "        \n",
    "        # Call the function that would normally be slow\n",
    "        result = process_data(\"https://example.com/api\")\n",
    "        \n",
    "        # Verify the result\n",
    "        assert result == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd019c",
   "metadata": {},
   "source": [
    "## Best Practice 9: Embrace Test-Driven Development (TDD)\n",
    "\n",
    "Test-Driven Development follows a simple cycle: Write a failing test, make it pass, then refactor. This approach helps ensure your code works as intended and leads to better design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a987b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example TDD workflow\n",
    "\n",
    "# Step 1: Write a failing test first\n",
    "def test_calculate_discount():\n",
    "    \"\"\"Test the calculate_discount function.\"\"\"\n",
    "    # Test normal discount calculation\n",
    "    assert calculate_discount(100, 20) == 80\n",
    "    \n",
    "    # Test 0% discount\n",
    "    assert calculate_discount(100, 0) == 100\n",
    "    \n",
    "    # Test 100% discount\n",
    "    assert calculate_discount(100, 100) == 0\n",
    "\n",
    "# Step 2: Implement the function to make the test pass\n",
    "def calculate_discount(price, discount_percent):\n",
    "    \"\"\"Calculate the final price after applying a discount.\n",
    "    \n",
    "    Args:\n",
    "        price: The original price\n",
    "        discount_percent: The discount percentage (0-100)\n",
    "        \n",
    "    Returns:\n",
    "        The final price after discount\n",
    "    \"\"\"\n",
    "    # Ensure discount is within valid range\n",
    "    if discount_percent < 0 or discount_percent > 100:\n",
    "        raise ValueError(\"Discount must be between 0 and 100\")\n",
    "        \n",
    "    discount_amount = price * (discount_percent / 100)\n",
    "    final_price = price - discount_amount\n",
    "    return final_price\n",
    "\n",
    "# Step 3: Refactor if needed while keeping tests passing\n",
    "# No refactoring needed for this simple example\n",
    "\n",
    "# Step 4: Add more tests for edge cases\n",
    "def test_calculate_discount_edge_cases():\n",
    "    \"\"\"Test calculate_discount with edge cases.\"\"\"\n",
    "    # Test with very small price\n",
    "    assert calculate_discount(0.01, 50) == 0.005\n",
    "    \n",
    "    # Test with invalid discount percentage\n",
    "    try:\n",
    "        calculate_discount(100, 101)\n",
    "        assert False, \"Expected ValueError but no exception was raised\"\n",
    "    except ValueError:\n",
    "        assert True\n",
    "        \n",
    "    try:\n",
    "        calculate_discount(100, -1)\n",
    "        assert False, \"Expected ValueError but no exception was raised\"\n",
    "    except ValueError:\n",
    "        assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f510908",
   "metadata": {},
   "source": [
    "## Best Practice 10: Test Edge Cases and Boundary Conditions\n",
    "\n",
    "Edge cases are the inputs at the extremes of the valid range. Testing them helps catch bugs that might otherwise go unnoticed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85be3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test\n",
    "def get_age_category(age):\n",
    "    \"\"\"Return age category based on age.\"\"\"\n",
    "    if not isinstance(age, (int, float)):\n",
    "        raise TypeError(\"Age must be a number\")\n",
    "        \n",
    "    if age < 0:\n",
    "        raise ValueError(\"Age cannot be negative\")\n",
    "    elif age < 13:\n",
    "        return \"Child\"\n",
    "    elif age < 20:\n",
    "        return \"Teenager\"\n",
    "    elif age < 65:\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return \"Senior\"\n",
    "\n",
    "# Testing edge cases\n",
    "def test_age_category_boundaries():\n",
    "    \"\"\"Test age category boundaries.\"\"\"\n",
    "    # Boundary values (exactly at the threshold)\n",
    "    assert get_age_category(0) == \"Child\"       # Minimum valid age\n",
    "    assert get_age_category(12) == \"Child\"      # Upper boundary for Child\n",
    "    assert get_age_category(13) == \"Teenager\"   # Lower boundary for Teenager\n",
    "    assert get_age_category(19) == \"Teenager\"   # Upper boundary for Teenager\n",
    "    assert get_age_category(20) == \"Adult\"      # Lower boundary for Adult\n",
    "    assert get_age_category(64) == \"Adult\"      # Upper boundary for Adult\n",
    "    assert get_age_category(65) == \"Senior\"     # Lower boundary for Senior\n",
    "    \n",
    "    # Invalid inputs\n",
    "    with pytest.raises(ValueError):\n",
    "        get_age_category(-1)  # Negative age\n",
    "        \n",
    "    with pytest.raises(TypeError):\n",
    "        get_age_category(\"25\")  # String instead of number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b5419",
   "metadata": {},
   "source": [
    "## Best Practice 11: Measure Test Coverage\n",
    "\n",
    "Test coverage tells you how much of your code is being tested. While 100% coverage doesn't guarantee bug-free code, it's a useful metric to identify untested parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a00d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to test\n",
    "def complex_function(x, y):\n",
    "    \"\"\"A function with multiple branches.\"\"\"\n",
    "    if x < 0:\n",
    "        return \"Negative x\"\n",
    "    elif y < 0:\n",
    "        return \"Negative y\"\n",
    "    elif x > y:\n",
    "        return \"x greater than y\"\n",
    "    elif x == y:\n",
    "        return \"x equals y\"\n",
    "    else:\n",
    "        return \"y greater than x\"\n",
    "\n",
    "# Write tests that achieve full coverage\n",
    "def test_complex_function_coverage():\n",
    "    \"\"\"Test all branches of complex_function.\"\"\"\n",
    "    assert complex_function(-1, 5) == \"Negative x\"\n",
    "    assert complex_function(5, -1) == \"Negative y\"\n",
    "    assert complex_function(10, 5) == \"x greater than y\"\n",
    "    assert complex_function(5, 5) == \"x equals y\"\n",
    "    assert complex_function(5, 10) == \"y greater than x\"\n",
    "\n",
    "# To run coverage analysis in the terminal:\n",
    "# pytest --cov=your_module test_your_module.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb570b7a",
   "metadata": {},
   "source": [
    "## Best Practice 12: Make Tests Deterministic\n",
    "\n",
    "Non-deterministic tests (flaky tests) that sometimes pass and sometimes fail are a major headache. Ensure your tests are reliable and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Function with non-deterministic behavior\n",
    "def get_random_choice(items):\n",
    "    \"\"\"Return a random item from the list.\"\"\"\n",
    "    return random.choice(items)\n",
    "\n",
    "# Bad: Non-deterministic test\n",
    "def test_random_choice_bad():\n",
    "    \"\"\"Test that might fail sometimes.\"\"\"\n",
    "    items = [1, 2, 3, 4, 5]\n",
    "    result = get_random_choice(items)\n",
    "    assert result in [1, 2, 3]  # Will fail if 4 or 5 is chosen\n",
    "\n",
    "# Good: Deterministic test using mock\n",
    "def test_random_choice_good():\n",
    "    \"\"\"Test with controlled randomness.\"\"\"\n",
    "    with patch('random.choice') as mock_choice:\n",
    "        # Force random.choice to return 3\n",
    "        mock_choice.return_value = 3\n",
    "        \n",
    "        items = [1, 2, 3, 4, 5]\n",
    "        result = get_random_choice(items)\n",
    "        \n",
    "        # Now we can make a specific assertion\n",
    "        assert result == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ee2cd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Effective unit testing is crucial for maintaining high-quality Python code. By following these best practices, you can create test suites that are:\n",
    "\n",
    "- Fast and efficient\n",
    "- Clear and maintainable\n",
    "- Reliable and deterministic\n",
    "- Comprehensive in coverage\n",
    "\n",
    "Remember that the primary goal of testing is to catch bugs early and provide confidence that your code works as expected. Good tests also serve as documentation, showing how your code is intended to be used.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Pytest Documentation](https://docs.pytest.org/)\n",
    "- [Python unittest Documentation](https://docs.python.org/3/library/unittest.html)\n",
    "- [Test-Driven Development with Python](https://www.obeythetestinggoat.com/)\n",
    "- [Effective Python Testing With Pytest](https://realpython.com/pytest-python-testing/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
